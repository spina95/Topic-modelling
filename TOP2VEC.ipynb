{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TOP2VEC.ipynb","provenance":[],"authorship_tag":"ABX9TyPCLU+t9UMNv8EssNykSLGH"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"V91-0gXBdECp","executionInfo":{"status":"ok","timestamp":1614444954631,"user_tz":-60,"elapsed":3211,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}}},"source":["import torch\r\n","import pandas as pd\r\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QbV_oqy6skn-","executionInfo":{"status":"ok","timestamp":1614444973776,"user_tz":-60,"elapsed":22342,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}},"outputId":"e895ca49-711f-448e-feb4-3daff3173ae8"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JhMlucXcsqtt","executionInfo":{"status":"ok","timestamp":1614444973778,"user_tz":-60,"elapsed":2282,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}},"outputId":"55ac1ac5-1248-4605-e506-5060ef19677c"},"source":["cd drive/MyDrive/Tesi/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Tesi\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4yA96JhVY6l8","executionInfo":{"status":"ok","timestamp":1614444975609,"user_tz":-60,"elapsed":885,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}}},"source":["import pandas as pd\r\n","import numpy as np\r\n","\r\n","f = open('gov_ita2.json',) \r\n","df = pd.read_json(f)\r\n","df = df[df.text != '']\r\n","df = df.reset_index()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"yOY6fgYVdan9"},"source":["from sklearn.datasets import fetch_20newsgroups\r\n","newsgroups_train = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\r\n","dataset = newsgroups_train.data[0:10000]\r\n","original_labels = newsgroups_train.target[0:10000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"df3FzBjfd2fa","executionInfo":{"status":"ok","timestamp":1611831083490,"user_tz":-60,"elapsed":1703,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}},"outputId":"ac3ce44a-9b99-4e9a-b5a3-24eec6d32b3a"},"source":["df = pd.DataFrame(dataset, columns=['text']) \r\n","df['original_labels'] = original_labels\r\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>original_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>My brother is in the market for a high-perform...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1)    I have an old Jasmine drive which I cann...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>GK&gt;I hear that tires for this car can get real...</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>\\nTod, I think you've misspoke.  If they're ba...</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>\\n\\n\\n\\n\\n\\nYep! Sounds good to me. suggestion...</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>Anyone familiar with this video card? What chi...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>\\n\\n\\n&lt; rest deleted &gt;\\n\\nAs a followup to my ...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text  original_labels\n","0     \\n\\nI am sure some bashers of Pens fans are pr...               10\n","1     My brother is in the market for a high-perform...                3\n","2     \\n\\n\\n\\n\\tFinally you said what you dream abou...               17\n","3     \\nThink!\\n\\nIt's the SCSI card doing the DMA t...                3\n","4     1)    I have an old Jasmine drive which I cann...                4\n","...                                                 ...              ...\n","9995  GK>I hear that tires for this car can get real...                7\n","9996  \\nTod, I think you've misspoke.  If they're ba...                8\n","9997  \\n\\n\\n\\n\\n\\nYep! Sounds good to me. suggestion...               12\n","9998  Anyone familiar with this video card? What chi...                3\n","9999  \\n\\n\\n< rest deleted >\\n\\nAs a followup to my ...                2\n","\n","[10000 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"SbBjQugYakS-","executionInfo":{"status":"ok","timestamp":1614445056438,"user_tz":-60,"elapsed":56486,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}},"outputId":"23a24d52-b227-4264-bb1f-fc3a7d1d5e53"},"source":["! pip install top2vec[sentence_encoders]"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting top2vec[sentence_encoders]\n","  Downloading https://files.pythonhosted.org/packages/64/b5/d35d1da937a5e544347c4082a3969a320ef31b38a499bbc673c7e1484b6e/top2vec-1.0.23-py3-none-any.whl\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.1.5)\n","Collecting hdbscan>=0.8.27\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/bb/59a75bc5ac66a9b4f9b8f979e4545af0e98bb1ca4e6ae96b3b956b554223/hdbscan-0.8.27.tar.gz (6.4MB)\n","\u001b[K     |████████████████████████████████| 6.4MB 6.0MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.5.0)\n","Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.5.1)\n","Collecting numpy>=1.20.0\n","  Using cached https://files.pythonhosted.org/packages/70/8a/064b4077e3d793f877e3b77aa64f56fa49a4d37236a53f78ee28be009a16/numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (3.6.0)\n","Requirement already satisfied: tensorflow; extra == \"sentence_encoders\" in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (2.4.1)\n","Requirement already satisfied: tensorflow-hub; extra == \"sentence_encoders\" in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.11.0)\n","Collecting tensorflow-text; extra == \"sentence_encoders\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/c0/c0fed4301f592c3b56638ae7292612c17d91a43891ba1aaf9636d535beae/tensorflow_text-2.4.3-cp37-cp37m-manylinux1_x86_64.whl (3.4MB)\n","\u001b[K     |████████████████████████████████| 3.4MB 39.2MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2.8.1)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.0.1)\n","Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (0.22.2.post1)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.15.0)\n","Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (0.29.22)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec[sentence_encoders]) (7.0.0)\n","Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.51.2)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.5.2)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->top2vec[sentence_encoders]) (4.2.0)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2.4.1)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.12)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.6.3)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.12.4)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.1.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.10.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.12.1)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.3.3)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.2.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.1.2)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.3.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.7.4.3)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2.10.0)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.32.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.36.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (53.0.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.34.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.4.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.27.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.3.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.3.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (4.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.2.8)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.4.0)\n","Building wheels for collected packages: hdbscan\n","  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdbscan: filename=hdbscan-0.8.27-cp37-cp37m-linux_x86_64.whl size=2311661 sha256=365f149b555cac64f2e4f54e7c4dbe4e5406fc92cbf96aa59623c69b364c37b8\n","  Stored in directory: /root/.cache/pip/wheels/42/63/fb/314ad6c3b270887a3ecb588b8e5aac50b0fad38ff89bb6dff2\n","Successfully built hdbscan\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: jaxlib 0.1.60+cuda101 has requirement numpy<1.20,>=1.12, but you'll have numpy 1.20.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, hdbscan, tensorflow-text, top2vec\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","Successfully installed hdbscan-0.8.27 numpy-1.20.1 tensorflow-text-2.4.3 top2vec-1.0.23\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":816},"id":"ktiu9HsQliVz","executionInfo":{"status":"ok","timestamp":1614444450910,"user_tz":-60,"elapsed":58986,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}},"outputId":"e8b91042-9497-45c6-ea9f-95b2456e9440"},"source":["!pip install top2vec"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting top2vec\n","  Downloading https://files.pythonhosted.org/packages/64/b5/d35d1da937a5e544347c4082a3969a320ef31b38a499bbc673c7e1484b6e/top2vec-1.0.23-py3-none-any.whl\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec) (1.1.5)\n","Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from top2vec) (0.5.1)\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec) (1.5.0)\n","Collecting numpy>=1.20.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/8a/064b4077e3d793f877e3b77aa64f56fa49a4d37236a53f78ee28be009a16/numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3MB)\n","\u001b[K     |████████████████████████████████| 15.3MB 321kB/s \n","\u001b[?25hCollecting hdbscan>=0.8.27\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/bb/59a75bc5ac66a9b4f9b8f979e4545af0e98bb1ca4e6ae96b3b956b554223/hdbscan-0.8.27.tar.gz (6.4MB)\n","\u001b[K     |████████████████████████████████| 6.4MB 42.0MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from top2vec) (3.6.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec) (2.8.1)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec) (1.4.1)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec) (0.5.2)\n","Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec) (0.51.2)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec) (0.22.2.post1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec) (7.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (1.15.0)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (1.0.1)\n","Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (0.29.22)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->top2vec) (4.2.0)\n","Requirement already satisfied: llvmlite>=0.30 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn>=0.5.1->top2vec) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (53.0.0)\n","Building wheels for collected packages: hdbscan\n","  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdbscan: filename=hdbscan-0.8.27-cp37-cp37m-linux_x86_64.whl size=2311676 sha256=0c12fc4346f51764e7e24074faf7363cb4c00893aefe07eca532e602700f4132\n","  Stored in directory: /root/.cache/pip/wheels/42/63/fb/314ad6c3b270887a3ecb588b8e5aac50b0fad38ff89bb6dff2\n","Successfully built hdbscan\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: jaxlib 0.1.60+cuda101 has requirement numpy<1.20,>=1.12, but you'll have numpy 1.20.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, hdbscan, top2vec\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","Successfully installed hdbscan-0.8.27 numpy-1.20.1 top2vec-1.0.23\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JGvIcouRlp3N","executionInfo":{"status":"ok","timestamp":1614445230862,"user_tz":-60,"elapsed":35441,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}},"outputId":"e6adbce7-c041-4d00-b2c2-f3f494fd7b3a"},"source":["from top2vec import Top2Vec\r\n","\r\n","model = Top2Vec(df.text.tolist(), embedding_model='universal-sentence-encoder-multilingual')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["2021-02-27 16:59:55,203 - top2vec - INFO - Pre-processing documents for training\n","INFO:top2vec:Pre-processing documents for training\n","2021-02-27 16:59:55,872 - top2vec - INFO - Downloading universal-sentence-encoder-multilingual model\n","INFO:top2vec:Downloading universal-sentence-encoder-multilingual model\n","2021-02-27 17:00:01,724 - top2vec - INFO - Creating joint document/word embedding\n","INFO:top2vec:Creating joint document/word embedding\n","2021-02-27 17:00:23,482 - top2vec - INFO - Creating lower dimension embedding of documents\n","INFO:top2vec:Creating lower dimension embedding of documents\n","2021-02-27 17:00:29,853 - top2vec - INFO - Finding dense areas of documents\n","INFO:top2vec:Finding dense areas of documents\n","2021-02-27 17:00:29,886 - top2vec - INFO - Finding topics\n","INFO:top2vec:Finding topics\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7efb9d3747a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7efb9d3747a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"wWVOZJ2ezdVA","executionInfo":{"status":"ok","timestamp":1614445237856,"user_tz":-60,"elapsed":527,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}}},"source":["reduced = model.hierarchical_topic_reduction(5)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0rxUHX4z428","executionInfo":{"status":"ok","timestamp":1614445125788,"user_tz":-60,"elapsed":536,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}},"outputId":"4145706e-184b-40ad-91ad-3b888244b68d"},"source":["model.get_num_topics(reduced=True)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"nGyBCe2xmxCK","executionInfo":{"status":"ok","timestamp":1614445240305,"user_tz":-60,"elapsed":531,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}}},"source":["topic_words, word_scores, topic_nums = model.get_topics(reduced=True)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVft1ISKnMcp","executionInfo":{"status":"ok","timestamp":1611831401846,"user_tz":-60,"elapsed":311450,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}},"outputId":"b52bc679-99eb-4f73-aa57-01db4fc765c5"},"source":["model.get_num_topics()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["63"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FjxttIqDpKZm","executionInfo":{"status":"ok","timestamp":1614445241449,"user_tz":-60,"elapsed":552,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}},"outputId":"81c145fc-b0dd-4929-bd45-dffcd1cbd51e"},"source":["topic_words"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['ministri', 'amministrativa', 'decreto', 'ministero',\n","        'pubbliche', 'segretario', 'ministers', 'ministro', 'parlamento',\n","        'pubblica', 'pubblici', 'costituzionali', 'cittadini',\n","        'presidenza', 'candidati', 'costituzionale', 'comunale',\n","        'dipartimento', 'pubblico', 'government', 'amministrativo',\n","        'aprile', 'amministrazioni', 'ordinario', 'nazionale',\n","        'amministrazione', 'concorso', 'governo', 'pubblicazione',\n","        'civile', 'gazzetta', 'territorio', 'politiche', 'nomina',\n","        'maggio', 'presidente', 'speciale', 'concorsi', 'straordinario',\n","        'novembre', 'regioni', 'proclami', 'campagna', 'statale',\n","        'pubblicata', 'council', 'provvedimenti', 'tutela', 'eventi',\n","        'marzo'],\n","       ['notifica', 'proclami', 'annullamento', 'ricorso', 'pubblici',\n","        'comunita', 'ordinario', 'comune', 'pubblica', 'pubblico',\n","        'pubbliche', 'ricorrente', 'comuni', 'applicata', 'comunale',\n","        'applicazione', 'approvazione', 'atto', 'decreto', 'avviso',\n","        'atti', 'ordinanza', 'ad', 'istanze', 'straordinario', 'sensi',\n","        'declaratoria', 'council', 'pubblicato', 'enti', 'allegati',\n","        'medesima', 'comunque', 'speciale', 'provvedimenti', 'dedicato',\n","        'iniziativa', 'cessazione', 'comunicato', 'recante', 'spot',\n","        'claim', 'fabbisogni', 'quale', 'autorita', 'deroga',\n","        'cittadini', 'che', 'amministrativo', 'nomina'],\n","       ['ministro', 'ministers', 'parlamento', 'ministri', 'presidente',\n","        'ministero', 'governo', 'segretario', 'presidenza', 'president',\n","        'government', 'amministrazioni', 'palazzo', 'amministrazione',\n","        'amministrativo', 'council', 'repubblica', 'commissario',\n","        'amministrativa', 'decreto', 'ufficio', 'politiche',\n","        'dipartimento', 'commissione', 'provvedimenti', 'republic',\n","        'coordinamento', 'costituzionali', 'cittadini', 'costituzionale',\n","        'febbraio', 'consiglio', 'preordinato', 'nomina', 'gestione',\n","        'pubbliche', 'spettanti', 'comunale', 'maggio', 'unione',\n","        'comunita', 'ottobre', 'candidati', 'predette', 'ordinanza',\n","        'pubblica', 'sala', 'medesima', 'autorita', 'ufficiale'],\n","       ['comunale', 'comunita', 'ordinario', 'comune', 'comuni',\n","        'pubbliche', 'pubblici', 'pubblica', 'applicazione', 'generale',\n","        'risorse', 'applicata', 'pubblico', 'amministrativa', 'decreto',\n","        'fonte', 'ricorso', 'standard', 'amministrativo', 'citta',\n","        'ricorrente', 'aprile', 'cittadini', 'amministrazioni',\n","        'costituzionali', 'ciascun', 'quale', 'ogni', 'tutti',\n","        'costituzionale', 'statuto', 'allegati', 'pubblicazione',\n","        'pubblicata', 'diffusa', 'locali', 'ufficiale', 'norme',\n","        'council', 'straordinario', 'dicembre', 'territorio',\n","        'approvazione', 'speciale', 'ordinanza', 'principi', 'tutte',\n","        'civile', 'amministrazione', 'ciascuna'],\n","       ['ministri', 'ministers', 'ministero', 'ministro',\n","        'amministrazioni', 'decreto', 'costituzionali', 'government',\n","        'governo', 'amministrativa', 'mille', 'statale', 'segretario',\n","        'amministrativo', 'provvedimenti', 'amministrazione',\n","        'cittadini', 'otto', 'parlamento', 'dipartimento', 'agosto',\n","        'pubbliche', 'gestione', 'quota', 'luglio', 'nazionale',\n","        'ciascun', 'intervento', 'nomina', 'straordinario', 'istanze',\n","        'speciale', 'interventi', 'territorio', 'ordinario', 'anno',\n","        'presidenza', 'presidente', 'paese', 'costituzionale',\n","        'attribuzione', 'ore', 'pubblico', 'proclami', 'ciascuna',\n","        'misure', 'servizi', 'tutela', 'destinatari', 'personale']],\n","      dtype='<U15')"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"DE1UalTu1dO7"},"source":["labels = model.get_documents_topics(list(range(len(df))), reduced=True)[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IE9uWimh15Es","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611834836650,"user_tz":-60,"elapsed":1140,"user":{"displayName":"ANDREA SPINAZZOLA","photoUrl":"","userId":"12266842702765378047"}},"outputId":"b926b7bc-6b81-4ca4-de80-1f2f36f90a8d"},"source":["labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0,  3,  7, ...,  4,  3, 13])"]},"metadata":{"tags":[]},"execution_count":32}]}]}